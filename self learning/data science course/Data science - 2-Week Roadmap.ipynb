{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Week Roadmap\n",
    "\n",
    "A 2-week roadmap for you, which builds on the topics from Joel Grus's \"Data Science from Scratch\" and incorporates additional resources to help you gain a deeper understanding of the subject. This roadmap includes practical projects that you can work on to apply your newfound knowledge.\n",
    "\n",
    "**Week 1**\n",
    "\n",
    "**Day 1: Data Exploration and Visualization**\n",
    "- Learn the basics of pandas: [10 minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)\n",
    "- Data Wrangling with pandas: [Data Wrangling with pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "- Learn the basics of Matplotlib: [Matplotlib tutorial](https://matplotlib.org/stable/tutorials/introductory/pyplot.html)\n",
    "- Introduction to seaborn: [seaborn tutorial](https://seaborn.pydata.org/tutorial.html)\n",
    "\n",
    "**Project 1**: Explore and visualize the [Titanic dataset](https://www.kaggle.com/c/titanic/data) using pandas, Matplotlib, and seaborn.\n",
    "\n",
    "**Day 2-3: Supervised Machine Learning and scikit-learn**\n",
    "- Introduction to scikit-learn: [Getting started with scikit-learn](https://scikit-learn.org/stable/getting_started.html)\n",
    "- Supervised learning algorithms: [Supervised learning tutorial](https://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html)\n",
    "- Model evaluation: [Model evaluation tutorial](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "\n",
    "**Project 2**: Predict survival on the Titanic using various supervised learning algorithms from scikit-learn. Evaluate the performance of your models.\n",
    "\n",
    "**Day 4: Unsupervised Machine Learning**\n",
    "- Unsupervised learning algorithms: [Unsupervised learning tutorial](https://scikit-learn.org/stable/tutorial/statistical_inference/unsupervised_learning.html)\n",
    "- Clustering with k-means: [k-means clustering](https://scikit-learn.org/stable/modules/clustering.html#k-means)\n",
    "\n",
    "**Project 3**: Perform customer segmentation using the [Mall Customer Segmentation dataset](https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python) with k-means clustering.\n",
    "\n",
    "**Day 5: Feature Engineering and Dimensionality Reduction**\n",
    "- Feature engineering: [Feature engineering guide](https://elitedatascience.com/feature-engineering-best-practices)\n",
    "- PCA for dimensionality reduction: [PCA tutorial](https://scikit-learn.org/stable/modules/decomposition.html#pca)\n",
    "\n",
    "**Project 4**: Apply feature engineering and PCA to improve the performance of your supervised learning models on the Titanic dataset.\n",
    "\n",
    "**Week 2**\n",
    "\n",
    "**Day 6-7: Introduction to Neural Networks and TensorFlow**\n",
    "- Neural Networks: [Neural Networks and Deep Learning book](http://neuralnetworksanddeeplearning.com/)\n",
    "- TensorFlow basics: [Get started with TensorFlow](https://www.tensorflow.org/tutorials/quickstart/beginner)\n",
    "\n",
    "**Project 5**: Classify handwritten digits using the [MNIST dataset](https://www.tensorflow.org/datasets/catalog/mnist) with TensorFlow.\n",
    "\n",
    "**Day 8-9: Deep Learning with Keras**\n",
    "- Keras introduction: [Keras guide](https://keras.io/guides/)\n",
    "- Convolutional Neural Networks (CNNs): [CNNs for visual recognition](http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "**Project 6**: Classify images using the [CIFAR-10 dataset](https://www.tensorflow.org/datasets/catalog/cifar10) with a CNN implemented in Keras.\n",
    "\n",
    "**Day 10-11: Natural Language Processing**\n",
    "- Introduction to NLP: [NLP with Python book, Chapter 1](https://www.nltk.org/book/ch01.html)\n",
    "- Text preprocessing: [Text preprocessing guide](https://www.kdnuggets.com/2018/03/text-data-preprocessing-walkthrough-python.html)\n",
    "- Text classification with scikit-learn: [Working with text data](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n",
    "\n",
    "**Project 7**: Sentiment analysis on the [IMDb movie reviews dataset](https://ai.stanford.edu/~amaas/data/sentiment/) using scikit-learn.\n",
    "\n",
    "**Day 12: Word Embeddings and Word2Vec**\n",
    "- Word embeddings: [Word embeddings tutorial](https://www.tensorflow.org/tutorials/text/word_embeddings)\n",
    "- Word2Vec: [Word2Vec explained](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa)\n",
    "\n",
    "**Project 8**: Train a Word2Vec model on a large text corpus, such as [Gutenberg books](https://web.eecs.umich.edu/~lahiri/gutenberg_dataset.html), and explore the generated embeddings.\n",
    "\n",
    "**Day 13: Recurrent Neural Networks (RNNs) and LSTMs**\n",
    "- RNNs and LSTMs: [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- Implementing LSTMs with Keras: [A ten-minute introduction to sequence-to-sequence learning in Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)\n",
    "\n",
    "**Project 9**: Build an RNN or LSTM model to generate text based on a large text corpus.\n",
    "\n",
    "**Day 14: Review and Next Steps**\n",
    "- Review the topics and projects from the past two weeks.\n",
    "- Identify areas where you need more practice or further study.\n",
    "- Plan your next steps in learning data science and AI, such as exploring reinforcement learning, unsupervised deep learning, or advanced NLP techniques like transformers.\n",
    "\n",
    "Throughout this roadmap, remember to consult the documentation for the various Python packages you'll be using, as well as online forums and communities such as Stack Overflow and the relevant subreddits on Reddit.\n",
    "\n",
    "As you work on these projects, feel free to ask me questions or seek guidance. Good luck on your learning journey!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matpotlib\n",
    "\n",
    "[Quick start guide](https://matplotlib.org/stable/tutorials/introductory/quick_start.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib graphs your data on Figures (e.g., windows, Jupyter widgets, etc.), each of which can contain one or more Axes. The simplest way of creating a Figure with an Axes is using pyplot.subplots. We can then draw some data on the Axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()  # Create a figure containing a single axes.\n",
    "ax.plot([1, 2, 3, 4], [1, 4, 2, 3])  # first list is x, second is y\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imo this is the simplest way to plot\n",
    "plt.plot([1, 2, 3, 4], [1, 4, 2, 3])  # first list is x, second is y\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see [cheat sheet](matplotlib_cheat_sheet.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure\n",
    "\n",
    "The Figure keeps track of all the child Axes, a smattering of ‘special’ artists (titles, figure legends, etc), and the canvas. (Don’t worry too much about the canvas, it is crucial as it is the object that actually does the drawing to get you your plot, but as the user it is more-or-less invisible to you). \n",
    "\n",
    "A Figure can contain any number of Axes, but will typically have at least one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()  # an empty figure with no Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()  # a figure with a single Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2)  # a figure with a 2x2 grid of Axes # note the s in subplots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axes\n",
    "An Axes is an Artist attached to a Figure that contains a region for plotting data, and usually includes two (or three in the case of 3D) *axis* objects (be aware of the difference between Axes and Axis) that provide ticks and tick labels to provide scales for the data in the Axes. Each Axes also has a title (set via set_title()), an x-label (set via set_xlabel()), and a y-label set via set_ylabel()).\n",
    "\n",
    "*It is basically a graph within the graph.*\n",
    "\n",
    "### Axis\n",
    "These objects set the scale and limits and generate ticks (the marks on the Axis) and ticklabels (strings labeling the ticks). The location of the ticks is determined by a Locator object and the ticklabel strings are formatted by a Formatter. The combination of the correct Locator and Formatter gives very fine control over the tick locations and labels.\n",
    "\n",
    "### Artist\n",
    "Basically, everything visible on the Figure is an Artist (even Figure, Axes, and Axis objects). This includes Text objects, Line2D objects, collections objects, Patch objects, etc. When the Figure is rendered, all of the Artists are drawn to the canvas. Most Artists are tied to an Axes; such an Artist cannot be shared by multiple Axes, or moved from one to another.\n",
    "\n",
    "## Types of inputs to plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best to convert to numpy arrays with np.asarray\n",
    "b = np.matrix([[1, 2], [3, 4]])\n",
    "b_asarray = np.asarray(b)\n",
    "b_asarray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\n",
    "\n",
    "# is equivalent to\n",
    "\n",
    "plt.figure(figsize=(5, 2.7), layout='constrained')\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling plots\n",
    "\n",
    "and how `n, bins, patches` looks in `ax.hist()` and interprets it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 115, 15\n",
    "x = mu + sigma * np.random.randn(10000)\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = ax.hist(x, 50, density=True, facecolor='C0', alpha=0.75)\n",
    "\n",
    "ax.set_xlabel('Length [cm]')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('Aardvark lengths\\n (not really)')\n",
    "ax.text(75, .025, r'$\\mu=115,\\ \\sigma=15$')\n",
    "ax.axis([55, 175, 0, 0.03])\n",
    "ax.grid(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pyplot tutorial\n",
    "## Introduction to pyplot\n",
    "\n",
    "`pyplot` is a collection of functions.  Each ``pyplot`` function makes some change to a figure:\n",
    "e.g., creates a figure, creates a plotting area in a figure, plots some lines\n",
    "in a plotting area, decorates the plot with labels, etc.\n",
    "\n",
    "In `matplotlib.pyplot` various states are preserved\n",
    "across function calls, so that it keeps track of things like\n",
    "the current figure and plotting area, and the plotting\n",
    "functions are directed to the current axes (please note that \"axes\" here\n",
    "and in most places in the documentation refers to the *axes*\n",
    "`part of a figure`\n",
    "and not the strict mathematical term for more than one axis).\n",
    "\n",
    "Generating visualizations with pyplot is very quick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([1, 2, 3, 4])\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be wondering why the x-axis ranges from 0-3 and the y-axis\n",
    "from 1-4.  **If you provide a single list or array to\n",
    "`~.pyplot.plot`, matplotlib assumes it is a\n",
    "sequence of y values, and automatically generates the x values for\n",
    "you.**  Since python ranges start with 0, the default x vector has the\n",
    "same length as y but starts with 0; therefore, the x data are\n",
    "``[0, 1, 2, 3]``.\n",
    "\n",
    "`~.pyplot.plot` is a versatile function, and will take an arbitrary number of\n",
    "arguments.  For example, to plot x versus y, you can write:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1, 2, 3, 4], [1, 4, 9, 16])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the style of your plot\n",
    "\n",
    "For every x, y pair of arguments, there is an optional third argument\n",
    "which is the format string that indicates the color and line type of\n",
    "the plot.  The letters and symbols of the format string are from\n",
    "MATLAB, and you concatenate a color string with a line style string.\n",
    "*The default format string is 'b-', which is a solid blue line*.  For\n",
    "example, to plot the above with red circles, you would issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1, 2, 3, 4], [1, 4, 9, 16], 'ro') # note the 'r' for red and 'o' for circles.\n",
    "plt.axis([0, 6, 0, 20])                     # The `.axis` function takes a list of `[xmin, xmax, ymin, ymax]`\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes x, y, (colour), x, y, (colour),... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# evenly sampled time at 200ms intervals\n",
    "t = np.arange(0., 5., 0.2)\n",
    "\n",
    "plt.plot(t, t, 'r--', t, t**2, 'bs', t, t**3, 'g^') # red dashes, blue squares and green triangles\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Plotting with keyword strings\n",
    "\n",
    "With a `DataFrame`, Matplotlib allows you to provide such an object with a keyword argument. If provided, you may generate plots with\n",
    "the strings corresponding to these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'a': np.arange(50),\n",
    "        'c': np.random.randint(0, 50, 50),\n",
    "        'd': np.random.randn(50)}\n",
    "\n",
    "data['b'] = data['a'] + 10 * np.random.randn(50)\n",
    "data['d'] = np.abs(data['d']) * 100\n",
    "\n",
    "plt.scatter('a', 'b', c='c', s='d', data=data) # so just notice the data=data\n",
    "plt.xlabel('entry a')\n",
    "plt.ylabel('entry b')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting with categorical variables\n",
    "\n",
    "It is also possible to create a plot using categorical variables.\n",
    "Matplotlib allows you to pass categorical variables directly to\n",
    "many plotting functions. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['group_a', 'group_b', 'group_c']\n",
    "values = [1, 10, 100]\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "\n",
    "plt.subplot(131)    # 1 row, 3 columns, 1st plot, equivalent to plt.subplot(1, 3, 1)\n",
    "plt.bar(names, values)\n",
    "plt.subplot(132)\n",
    "plt.scatter(names, values)\n",
    "plt.subplot(133)\n",
    "plt.plot(names, values)\n",
    "plt.suptitle('Categorical Plotting')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Controlling line properties\n",
    "\n",
    "Lines have many attributes that you can set: linewidth, dash style,\n",
    "antialiased, etc.  There are\n",
    "several ways to set line properties\n",
    "\n",
    "\n",
    "* Use keyword arguments:\n",
    "      plt.plot(x, y, **linewidth**=2.0)\n",
    "\n",
    "\n",
    "* Use the setter methods:\n",
    "\n",
    "     ```python\n",
    "      line, = plt.plot(x, y, '-')\n",
    "      line.set_antialiased(False) # turn off antialiasing```\n",
    "      \n",
    "* Use `.setp`\n",
    "\n",
    "```python\n",
    "      lines = plt.plot(x1, y1, x2, y2)\n",
    "      # use keyword arguments\n",
    "      plt.setp(lines, color='r', linewidth=2.0)\n",
    "```\n",
    "\n",
    "## Working with multiple figures and axes\n",
    "\n",
    "MATLAB, and `.pyplot`, have the concept of the current figure\n",
    "and the current axes.  All plotting functions apply to the current\n",
    "axes.  \n",
    "\n",
    "The function `~.pyplot.gca` (Get the Current Axes) returns the current axes, and `~.pyplot.gcf` returns the current\n",
    "figure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(t):\n",
    "    return np.exp(-t) * np.cos(2*np.pi*t)\n",
    "\n",
    "t1 = np.arange(0.0, 5.0, 0.1)\n",
    "t2 = np.arange(0.0, 5.0, 0.02)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(t1, f(t1), 'bo', t2, f(t2), 'k')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(t2, np.cos(2*np.pi*t2), 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can clear the current figure with `~.pyplot.clf`\n",
    "and clear everything with `~.pyplot.close`.\n",
    "\n",
    "## Working with text\n",
    "\n",
    "`~.pyplot.text` can be used to add text in an arbitrary location, and\n",
    "`~.pyplot.xlabel`, `~.pyplot.ylabel` and `~.pyplot.title` are used to add\n",
    "text in the indicated locations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 100, 15\n",
    "x = mu + sigma * np.random.randn(10000)\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(x, 50,\n",
    "                            density=True, \n",
    "                            # cumulative=True,           # good to know. This is a density function. \n",
    "                            # facecolor='g', alpha=0.75\n",
    "                            )\n",
    "\n",
    "\n",
    "plt.xlabel('Smarts')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Histogram of IQ')\n",
    "plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n",
    "plt.axis([40, 160, 0, 0.03])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using mathematical expressions in text\n",
    "\n",
    "Matplotlib accepts TeX equation expressions in any text expression.\n",
    "For example to write the expression $\\sigma_i=15$ in the title,\n",
    "you can write a TeX expression surrounded by dollar signs::\n",
    "```python\n",
    "    plt.title(r'$\\sigma_i=15$')\n",
    "```\n",
    "The ``r`` preceding the title string is important -- it signifies\n",
    "that the string is a *raw* string and not to treat backslashes as\n",
    "python escapes.  \n",
    "\n",
    "### Annotating text\n",
    "\n",
    "The uses of the basic `~.pyplot.text` function above\n",
    "place text at an arbitrary position on the Axes.  A common use for\n",
    "text is to annotate some feature of the plot, and the\n",
    "`~.pyplot.annotate` method provides helper\n",
    "functionality to make annotations easy.  In an annotation, there are\n",
    "two points to consider: the location being annotated represented by\n",
    "the argument ``xy`` and the location of the text ``xytext``.  Both of\n",
    "these arguments are ``(x, y)`` tuples.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic and other nonlinear axes\n",
    "\n",
    "`matplotlib.pyplot` supports not only linear axis scales. Changing the scale of an axis is easy:\n",
    "\n",
    "    plt.xscale('log')\n",
    "\n",
    "An example of four plots with the same data and different scales for the y-axis\n",
    "is shown below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "# make up some data in the open interval (0, 1)\n",
    "y = np.random.normal(loc=0.5, scale=0.4, size=1000)\n",
    "y = y[(y > 0) & (y < 1)]\n",
    "y.sort()\n",
    "x = np.arange(len(y))\n",
    "\n",
    "# plot with various axes scales\n",
    "plt.figure()\n",
    "\n",
    "# linear\n",
    "plt.subplot(221)\n",
    "plt.plot(x, y)\n",
    "plt.yscale('linear')\n",
    "plt.title('linear')\n",
    "plt.grid(True)\n",
    "\n",
    "# log\n",
    "plt.subplot(222)\n",
    "plt.plot(x, y)\n",
    "plt.yscale('log') # note the 'log' here\n",
    "plt.title('log')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to add your own scale, see `matplotlib.scale` for\n",
    "details.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seaborn tutorial\n",
    "\n",
    "see [here](https://seaborn.pydata.org/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Apply the default theme\n",
    "sns.set_theme()\n",
    "\n",
    "# Load an example dataset\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "\n",
    "# Create a visualization\n",
    "sns.relplot(\n",
    "    data=tips,\n",
    "    x=\"total_bill\", \n",
    "    y=\"tip\", \n",
    "    col=\"time\",\n",
    "    hue=\"smoker\", \n",
    "    style=\"smoker\", \n",
    "    size=\"size\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we provided only the names of the variables and their roles in the plot. Unlike when using matplotlib directly, it wasn’t necessary to specify attributes of the plot elements in terms of the color values or marker codes. Behind the scenes, seaborn handled the translation from values in the dataframe to arguments that matplotlib understands. This declarative approach lets you stay focused on the questions that you want to answer, rather than on the details of how to control matplotlib.\n",
    "\n",
    "The function `relplot()` is named that way because it is designed to visualize many different **statistical relationships**. While scatter plots are often effective, relationships where one variable represents a measure of time are better represented by a line. The relplot() function has a convenient kind parameter that lets you easily switch to this alternate representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = sns.load_dataset(\"dots\")\n",
    "sns.relplot(\n",
    "    data=dots, \n",
    "    # kind=\"line\",    # note how the line is a kind of relplot()\n",
    "    x=\"time\", \n",
    "    y=\"firing_rate\", \n",
    "    col=\"align\",\n",
    "    hue=\"choice\", \n",
    "    size=\"coherence\", \n",
    "    style=\"choice\",\n",
    "    facet_kws=dict(sharex=False),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the size and style parameters are used in both the scatter and line plots, but they affect the two visualizations differently: changing the marker area and symbol in the scatter plot vs the line width and dashing in the line plot. We did not need to keep those details in mind, letting us focus on the overall structure of the plot and the information we want it to convey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many seaborn functions will automatically perform the statistical estimation that is necessary to answer these questions:\n",
    "\n",
    "fmri = sns.load_dataset(\"fmri\")\n",
    "sns.relplot(\n",
    "    data=fmri, \n",
    "    kind=\"line\",\n",
    "    x=\"timepoint\", \n",
    "    y=\"signal\", \n",
    "    col=\"region\",\n",
    "    hue=\"event\", \n",
    "    style=\"event\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When statistical values are estimated, seaborn will use bootstrapping to compute confidence intervals and draw error bars representing the uncertainty of the estimate.\n",
    "\n",
    "Statistical estimation in seaborn goes beyond descriptive statistics. For example, it is possible to enhance a scatterplot by including a linear regression model (and its uncertainty) using `lmplot()`:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lmplot()\n",
    "for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=tips, x=\"total_bill\", y=\"tip\", col=\"time\", hue=\"smoker\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### displot()\n",
    "\n",
    "and histplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for distributional representations / histograms etc seaborns uses displot\n",
    "sns.displot(data=tips, x=\"total_bill\", col=\"time\", kde=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these show how total bill is not a normal distribution. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jointplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")\n",
    "sns.jointplot(data=penguins, x=\"flipper_length_mm\", y=\"bill_length_mm\", hue=\"species\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pairplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=penguins, hue=\"species\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2-3\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/basic/tutorial.html#introduction\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/statistical_inference/unsupervised_learning.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "\n",
    "## Some essential questions I asked and got answered:\n",
    "\n",
    "#### 1. **How to plot the distribution of random variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generate 1000 random variables from a normal distribution\n",
    "random_variables = np.random.normal(0, 1, 1000)\n",
    "\n",
    "# Plot the distribution of the random variables\n",
    "sns.histplot(random_variables, \n",
    "             kde=True             # to draw a line through it\n",
    "             )\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Random Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Create a histogram of the 'tip' column\n",
    "sns.histplot(tips['tip'], stat='density', binwidth=0.1,  color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the normal distribution based on the fitted parameters\n",
    "x_norm = np.linspace(tips['tip'].min(), tips['tip'].max())\n",
    "\n",
    "# with a normal distribution to the 'tip' data\n",
    "mu, sigma = stats.norm.fit(tips['tip'])\n",
    "y_norm = stats.norm.pdf(x_norm, mu, sigma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x_norm` returns a numpy array `numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0)`: With evenly spaced numbers over a specified interval.\n",
    "\n",
    "`y_norm` is a Probability density function with `pdf(x, loc=0, scale=1)`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the normal distribution overlay\n",
    "plt.plot(x_norm, y_norm, color=\"green\", label=f\"Normal dist. (μ={mu:.2f}, σ={sigma:.2f})\")\n",
    "plt.title(\"Tip Distribution\")\n",
    "plt.xlabel(\"Tip\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. **how to plot dependent variables and show how they correlate with each other**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "feature_names = iris.feature_names\n",
    "target = iris.target\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "df = pd.DataFrame(data, columns=feature_names)\n",
    "df['target'] = target\n",
    "\n",
    "# Create a pairplot\n",
    "sns.pairplot(df, hue='target')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, the iris dataset is loaded and converted into a DataFrame. Then, `sns.pairplot(df, hue='target')` is used to create a pairplot. The `hue='target'` option colors the points according to their class, which makes it easier to see how the features correlate with the target variable.\n",
    "\n",
    "Each plot on the diagonal shows the distribution of a single feature, and the plots off the diagonal show the relationships between pairs of features. By looking at these plots, you can see how the features correlate with each other and with the target variable.\n",
    "\n",
    "### The diagonal uses KDE, Kernel Density Estimation.\n",
    "\n",
    "It's a technique used to smooth a histogram and create an estimate of the probability density function (PDF) of a random variable.\n",
    "\n",
    "A histogram can be noisy or misleading depending on how the bins (the ranges of values) are chosen, and they don't give a smooth, continuous estimate of the underlying distribution. \n",
    "\n",
    "KDE addresses these issues by placing a continuous \"kernel\" function on each data point. The kernels are then summed to create a smooth estimate of the distribution. The kernel functions are usually Gaussian, but other shapes can be used as well.\n",
    "\n",
    "In data visualization, KDE is often used to create smoothed versions of histograms or to estimate the distribution of data in scatter plots. It's a useful technique for understanding the shape of the data distribution, especially when the number of data points is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(tips, diag_kind='kde')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. numpy arrays**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X` is the samples matrix (or design matrix). The size of X is typically (n_samples, n_features), which means that samples are represented as rows and features are represented as columns.\n",
    "\n",
    "`y` is the target variable. \n",
    "\n",
    "Both X and y are usually expected to be *numpy arrays*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.ndim # and .shape give the np.array() dimensions and shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of a numpy array tells you **how many dimensions** the array has and **how many elements are in each dimension**. For example, the shape (1, 3) means that the array is 2-dimensional, with 1 (unnecessary) element in the first dimension and 3 elements in the second dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0,0] # gives the index for each dimension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-dimensional arrays should be seen as matrices: \n",
    "\n",
    "a 2 dimensional array, like:\n",
    "\n",
    "```python\n",
    "    b = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "```\n",
    "\n",
    "has each 2 samples and 3 features. \n",
    "\n",
    "**Each sample is a row, each feature is a column.**\n",
    "\n",
    "| label | Col 1 | Col 2 | Col 3 |\n",
    "| :--: | :--: | :--: | :--: |\n",
    "| measurement 1 | 1 | 2 | 3 |\n",
    "| measurement 2 | 4 | 5 | 6 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 3-dimensional array, like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-dimensional array\n",
    "c = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sum = c + 5 # the book develops all this vector arithmetic from scratch: add, subtract, scalar_multiply (which multiplies with a constant)\n",
    "c_sum           # the book goes on: vector_mean, dot product, sum of squares, magnitude (square root of sum of squares), and distance*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "has sublists as matrices, which in turn have sublists as rows. And these matrices are also behind each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0,1,1] # is the index of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-dimensional array\n",
    "d = np.array([\n",
    "    [\n",
    "        [[1, 2, 3], [4, 5, 6]], \n",
    "        [[7, 8, 9], [10, 11, 12]]\n",
    "    ], \n",
    "    [\n",
    "        [[13, 14, 15], [16, 17, 18]], \n",
    "        [[19, 20, 21], [22, 23, 24]]\n",
    "    ]\n",
    "])\n",
    "d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, d is a 4-dimensional array containing two 3-dimensional arrays. Each of these 3-dimensional arrays contains two 2-dimensional arrays, and each of these 2-dimensional arrays contains two 1-dimensional arrays.\n",
    "\n",
    "You can access elements of a 4-dimensional array using four indices. The first index selects which 3-dimensional array to access, the second index selects which 2-dimensional array within that 3-dimensional array to access, the third index selects which 1-dimensional array within that 2-dimensional array to access, and the fourth index selects which element within that 1-dimensional array to access.\n",
    "\n",
    "For example, d[1, 0, 1, 2] would give the value in the second 3-dimensional array, first 2-dimensional array, second 1-dimensional array, and third element, which is 18 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that you can get any sublist by index \n",
    "d[0,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *as one of the kinds of vector arithmatic the book defines is distance, here's numpy does it: \n",
    "# note how it uses its linear algebra module, the submodule norm in specific which does vector arhitmetic\n",
    "\n",
    "# Define two 2-dimensional vectors (arrays)\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "b = np.array([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "# Calculate the Euclidean distance between a and b\n",
    "distance = np.linalg.norm(a - b)\n",
    "\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# 10 random numbers in one dimension\n",
    "one_d = np.random.rand(10)\n",
    "print(\"One dimension:\\n\", one_d)\n",
    "\n",
    "# 10 random numbers in two dimensions (5 rows, 2 columns)\n",
    "two_d = np.random.rand(5, 2)\n",
    "print(\"\\nTwo dimensions:\\n\", two_d)\n",
    "\n",
    "# 10 random numbers in three dimensions (2 layers, 5 rows, 2 columns)\n",
    "three_d = np.random.rand(2, 5, 2)\n",
    "print(\"\\nThree dimensions:\\n\", three_d)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: **layers**\n",
    "\n",
    "Also note that when you 'print' an array it's not seperated by commas. However, when you do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pandas dataframe columns translate to dimensions. \n",
    "\n",
    "> In linear regression, I am to find the coefficients (betas) for each dimension. These are not vector representations though. That's where i'm confused. \n",
    "\n",
    "\n",
    "In the context of linear regression, each column in your DataFrame represents a different dimension or > **feature** < of your data. Each row in the DataFrame represents a different observation or data point.\n",
    "\n",
    "For example, let's say you have a DataFrame with three columns: 'Height', 'Weight', and 'Age'. Each of these columns represents a different dimension of your data. If you were to perform a linear regression with 'Height' as your dependent variable and 'Weight' and 'Age' as your independent variables, you would be fitting a plane in three-dimensional space (Height, Weight, Age) that best fits your data.\n",
    "\n",
    "The coefficients you get from the linear regression represent the relationship between each independent variable and the dependent variable. For example, the coefficient for 'Weight' represents how much 'Height' is expected to change for a one-unit increase in 'Weight', assuming 'Age' is held constant.\n",
    "\n",
    "In this sense, \n",
    "> the **coefficients are not vector representations** of your data. Instead, they are **scalar values** that describe the relationship between your variables. The vector representation of a data point would be the list of all its feature values. \n",
    "> \n",
    "For example, a person might be represented by the vector [Height, Weight, Age]."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. f-strings with list comprehensions and decimal formatting**\n",
    "\n",
    "Something else I've been quite impressed by is how you can write a f-string in a list comprehensions in an attribute:\n",
    "\n",
    "```python\n",
    "    df = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(X.shape[1])])\n",
    "```\n",
    "this outputs columns:\n",
    "> feature_1 feature_2 etc.\n",
    "\n",
    "Another cool thing is writing the variable like this `{variable:.2f}` to reduce the number decimals."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Day 5: Feature Engineering and Dimensionality Reduction**\n",
    "\n",
    "- Feature engineering: [Feature engineering guide](https://elitedatascience.com/feature-engineering-best-practices)\n",
    "\n",
    "\n",
    "\n",
    "## Feature engineering:\n",
    "\n",
    "**Indicator Variables**\n",
    "\n",
    "The first type of feature engineering involves using indicator variables to isolate key information.\n",
    "\n",
    "\n",
    "- eg. from thresholds: Let’s say you’re studying alcohol preferences by U.S. consumers and your dataset has an age feature. You can create an indicator variable for age >= 21 to distinguish subjects who were over the legal drinking age.\n",
    "\n",
    "Indicator variables can be created from thresholds, combine multiple features, from special events, or for groups of classes:\n",
    "\n",
    "**Interaction Features**\n",
    "\n",
    "some features can be combined to provide more information than they would as individuals. \n",
    "\n",
    "- Sum of two features: Let’s say you wish to predict revenue based on preliminary sales data. You have the features sales_blue_pens and sales_black_pens. You could sum those features if you only care about overall sales_pens.\n",
    "\n",
    "Look for opportunities to take the sum, difference, product, or quotient of multiple features. Think of built date and sold date to create an age feature, or price and customers to create a revenue stream feature.\n",
    "\n",
    "**External Data**\n",
    "\n",
    "This can lead to some of the biggest breakthroughs in performance. Eg, one way quantitative hedge funds perform research is by layering together different streams of financial data.\n",
    "\n",
    "- time series data: allows layering-in any other time-series data\n",
    "- APIs\n",
    "- Geocoding: see this free api https://geoservices.tamu.edu/Services/Geocode/WebService/Details/\n",
    "\n",
    "**Error Analysis (Post-Modeling)**\n",
    "\n",
    "Analyse misclassified or high error observations.\n",
    "\n",
    "You can then try collecting more data, splitting the problem apart, or engineering new features that address the errors. To use error analysis for feature engineering, you’ll need to understand why your model missed its mark."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside on iterators\n",
    "\n",
    "I want to cycle through a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = iter([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "a = itertools.cycle([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = iter(['change_prompt', 'change_prompt2', 'change_prompt3', 'change_prompt4']) # (input=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joh_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
