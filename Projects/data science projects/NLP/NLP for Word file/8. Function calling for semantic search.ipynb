{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\"type\": \"function\",\n",
    "     \"function\": {\"name\": \"similarity_search\",\n",
    "     \"description\": \"Use this function to answer questions about specific topics. Pass all meaningful words as a query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"search_term\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"description\": \"The meaningful string, stripped of stopwords and uninformative words.\"\n",
    "                        },                  \n",
    "                    },\n",
    "                \"required\": [\"a search_term\"]}}}]\n",
    "\n",
    "similarity_search = \"drunken night\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.chat.completions.create(model=\"gpt-3.5-turbo-0613\", # \"gpt-4\",\n",
    "                            messages=[\n",
    "                                {\"role\": \"user\", \"content\": f\"What would johannes say about: {similarity_search}?\"}],\n",
    "                            max_tokens=1000,\n",
    "                            tools=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='call_pN7yGn8svAKdRN2NXqLJu40D', function=Function(arguments='{\\n  \"search_term\": \"drunken night\"\\n}', name='similarity_search'), type='function')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The supernova copilot as a model\n",
    "\n",
    "note that i should force the model into funciton calls each time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json, time\n",
    "\n",
    "client= OpenAI()\n",
    "\n",
    "def openai_stream(search_term):  \n",
    "    response = client.chat.completions.create(\n",
    "                                model=\"gpt-4-1106-preview\",\n",
    "                                messages=[{\"role\": \"user\", \"content\": f\"What would johannes say about: {search_term}?\"}], \n",
    "                                stream=True,\n",
    "                                temperature=0.4,\n",
    "                                max_tokens=1024,\n",
    "                                # tool_choice={\"type: \"function\", \"function\": {\"name\": \"similarity_search\"}},\n",
    "                                tools=functions,\n",
    "                                ) # type: ignore\n",
    "    return response\n",
    "\n",
    "def stream_chunks(text):\n",
    "    words = text.split(\" \")\n",
    "    for word in words:\n",
    "        time.sleep(0.1)\n",
    "        yield word + ' ' # was json\n",
    "\n",
    "def openai_call(search_term:str):\n",
    "    arguments = \"\"\n",
    "    name = \"\"\n",
    "    tool_call_id = \"\"\n",
    "    try: \n",
    "        for res in openai_stream(search_term):\n",
    "            choice = res.choices[0]\n",
    "            delta = choice.delta\n",
    "            if delta.tool_calls:\n",
    "                for tool_call in delta.tool_calls:\n",
    "                    # if multiple tool calls i'd have to deal with lists of these:\n",
    "                    name += tool_call.function.name or ''\n",
    "                    arguments += tool_call.function.arguments or ''\n",
    "                    tool_call_id += tool_call.id or ''\n",
    "                    \n",
    "            if choice.finish_reason and 'tool_calls' in choice.finish_reason:\n",
    "                print(\"function call: %s %s\", name, arguments, id)\n",
    "                args = json.loads(arguments)\n",
    "                data = None\n",
    "                \n",
    "                # function_to_call = globals().get(name)\n",
    "                if 'similarity_search' in name:\n",
    "                    print('similarity_search is in name')\n",
    "                    \n",
    "                    data = similarity_search(**args)\n",
    "                    if data:\n",
    "                        yield from interpreting_data(tool_call_id, search_term, name, args, data) \n",
    "                else: \n",
    "                    print('similarity_search is not in name')\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(\"An exception: \", e.args, e.with_traceback)\n",
    "        yield from stream_chunks(f\"Sorry, I'm having some trouble. I forwarded the error to our tech team. {e}\")\n",
    "        \n",
    "def interpreting_data(tool_call_id, search_term:str, name:str, args:str, data:str): # generator\n",
    "    full_response = ''\n",
    "    completion_res = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        temperature=0,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Wat schrijft de auteur over {search_term}?\"},\n",
    "                  {\"role\": \"assistant\", \"content\": 'null', 'tool_calls': [{'id': tool_call_id, 'function': {\"name\": name,'arguments': str(args)}, 'type': 'function'}]},\n",
    "                  {\"tool_call_id\": tool_call_id, \"role\": \"tool\", \"name\": name, \"content\": data} # type: ignore\n",
    "                  ],\n",
    "        stream=True,\n",
    "        tools=functions) # type: ignore\n",
    "    try:\n",
    "        for res in completion_res:\n",
    "            content_chunk = res.choices[0].delta.content\n",
    "            if content_chunk:\n",
    "                full_response += content_chunk\n",
    "                yield content_chunk # was json   \n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"interpreting_data returned an unexpected error: {e}\") from e\n",
    "    \n",
    "# semantic search\n",
    "def similarity_search(search_term, results = 3):\n",
    "    print(\"function call with search_term\", search_term)\n",
    "    \n",
    "    df = pd.read_pickle(\"df_topic_model_all_v2\")\n",
    "    df = df[df['mask']].copy()\n",
    "    embeddings = df.normal_embeddings.tolist()\n",
    "    user_text_embedding = sentence_model.encode(sentences=[search_term])\n",
    "    cosine_similarities = cosine_similarity(user_text_embedding, embeddings)\n",
    "    df['similarity'] = cosine_similarities.flatten()\n",
    "    df_pickle_clean_sorted = df.sort_values(by='similarity', ascending=False)\n",
    "    json = df_pickle_clean_sorted[['texts', 'similarity']].iloc[:results].to_json(orient='records')\n",
    "    return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function call: %s %s similarity_search {\"search_term\":\"een diepe crisis\"} <built-in function id>\n",
      "similarity_search is in name\n",
      "function call with search_term een diepe crisis\n",
      "De auteur schrijft over een diepe crisis in verschillende contexten. Hier zijn enkele fragmenten die de auteur heeft geschreven over situaties die kunnen worden geïnterpreteerd als een diepe crisis:\n",
      "\n",
      "1. De auteur beschrijft een gevoel van reddeloosheid en overweldiging door bureaucratie en administratieve rompslomp in sociale instellingen zoals de Hulpkas of VDAB. Er wordt een beeld geschetst van een gebrek aan arbeidsvreugde en een eindeloze wildgroei van formulieren en procedures.\n",
      "\n",
      "2. Er wordt gesproken over een persoonlijke crisis, waarbij de auteur een behoefte voelt om zich uit te drukken en zijn ziel uit te smeren over woorden. De auteur voelt zich echter beklemd en geïsoleerd door de confrontatie met anderen die zijn woorden beoordelen op autoriteit in plaats van inhoud.\n",
      "\n",
      "3. De auteur reflecteert op de spanning veroorzaakt door fenomenologische onzekerheid en stelt een Copernicaanse wending voor waarbij de bende het middelpunt inneemt boven normen en hogere beginselen. Dit zou een licht moeten werpen op de logica van het voorgaande en een antwoord moeten bieden op de vraag wat er na het post-structuralisme komt.\n",
      "\n",
      "Deze fragmenten tonen aan dat de auteur diepe crises verkent op zowel een maatschappelijk als persoonlijk niveau, en ook in de context van filosofische en epistemologische vraagstukken."
     ]
    }
   ],
   "source": [
    "for i in openai_call('een diepe crisis'):\n",
    "    print(i, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this wasn't clear in the docs:\n",
    "\n",
    "- function calling vs tool_calls\n",
    "\n",
    "```py\n",
    "# function calls need this before the \"role\": \"function\"\n",
    "{\"role\": \"assistant\", \"content\": 'null', \"function_call\": {\"name\": name, \"arguments\": args}}\n",
    "\n",
    "\n",
    "# tool calls need this line\n",
    "{\"role\": \"assistant\", \"content\": 'null', 'tool_calls': {'id': tool_call_id, 'function': { 'arguments': args, 'type':'function'}}}\n",
    "```\n",
    "\n",
    "\n",
    "this is an object of the class a ChatCompletionMessageToolCall, as seen when inspecting the output of a (non-streaming) `response.choices[0].message` object:\n",
    "\n",
    "```py\n",
    "\n",
    "from openai.types.chat.chat_completion_message import ChatCompletionMessageToolCall\n",
    "\n",
    "\n",
    "tool_call = ChatCompletionMessageToolCall()\n",
    "```\n",
    "## This shows (some) of the required inputs when instantiating the class as required inputs\n",
    "\n",
    "Such as id, function, etc.\n",
    "\n",
    ">  tool_calls=[ChatCompletionMessageToolCall(id='call_MgpkBPSnKyt8jtcOvESazlgF', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_current_weather'), type='function')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding model on cloud run?\n",
    "\n",
    "Hugging face advertises the API inference. This does similarity search like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "API_TOKEN = os.getenv('HUGGINGFACE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": {\n",
    "\t\t\"source_sentence\": \"That is a happy person\",\n",
    "\t\t\"sentences\": [\n",
    "\t\t\t\"That is a happy dog\",\n",
    "\t\t\t\"That is a very happy person\",\n",
    "\t\t\t\"Today is a sunny day\"\n",
    "\t\t]\n",
    "\t},\n",
    "})\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: i'd have to upload and download the entire array each time and basically redo all embeddings each time. Probably not cost effective. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_bs = [{\"texts\":\"Ik stond in monaco naast mijn nieuwe Porsche GT3 toen hij met z\\u2019n afstandsbediening naar mijn wagen kwam gelopen. Piebiep-biep. Het was ook Porschesleutel, ik herkende hem. \\u201cHah,\\u201d lachte hij. En hij liep lachend verder, naar de auto die voor d emijne stond geparkeerd. Het was mij nog niet echt opgevallen, maar het was krek dezelfde. Ik lachte naar hem: je hebt echt krek dezelfde als ik. Ja, zei hij. Hij was een visiounair een groot architectenbureau, zei hij. X was zijn naam. Hij was nu bezig aan een brochure over scholenbouw. Hij vertelde me er alles over. Over zijn iPads, zijn motors, zijn beeldschone vrouw, zijn onverzadigbare minnares. We hebben liters champagne achterover geklutst, daar samen op de dijk. Heerlijk.\\n\",\"similarity\":0.3990037441},{\"texts\":\"Review van Geert Maks In Europa\\nWaar waren we ook alweer gebleven?\\nGisterenavond zag ik de laatste aflevering van Geert Maks magnum opum In Europa. Na zijn boek van 852 wonderlijke bladzijden was de documentaire met zijn 35 afleveringen en 18 en een half uur aan beeldmateriaal een leuke aanvulling.\\nOm mijn algemene indruk in \\u00e9\\u00e9n woord weer te geven: gepriviligeerd. Ik voelde me gepriviligeerd een inkijk te hebben mogen nemen in zijn perspectief. Geert Mak is een oprechte, bescheiden vakman en dat werkt inspirerend.\\nIn 2004 kwam het boek uit. In Nederland kreeg hij een eredoctoraat (hij is geen historicus maar jurist van opleiding). Het werd in 14 talen vertaald en was een groot succes in Nederland, Belgi\\u00eb, Duitsland, Engeland en Frankrijk. De (Nederlandstalige) serie kwam van 2007 tot 2009 op tv en is online te bekijken op:\\nDit verklaart wellicht al een deel van die algemene indruk. Maar zijn ware verdienste ligt ongetwijfeld in de beeldenrijke inkleuring die hij aan het tijdvak heeft weten te geven. Geert Mak is een verhaalverteller, en de spreekwoordelijke beelden staan in mijn geheugen gegrift.\\nIn de documentaire ging de voorkeur veel meer uit naar de perspectieven van mensen die het meemaakten. Daardoor het succes vaak kwam af te hangen van het charisma van de personen die voor de lens werden opgevoerd.\\nZo is er de aflevering over de foto van het \\u201cvolksduits\\u201d meisje in Polen wellicht het best geslaagd in dat opzet. Het brengt met een zeer herkenbaar referentiepunt die vergeten geschiedenis van het Generaalgouvernement in Polen weer.\\nHet boek volgt een reistraject. Telkens behandelt hij een steeds variabele historische tijdspanne in contrast met zijn reisimpressies. Elk deel begint dan ook met een kaartje waarop het stuk van de reisweg wordt getoond, en vervolgens wordt elke plek in kleine, makkelijk verteerbare stukjes beschreven.\\nDe historische scharnierpunten komen echter ruimschoots aan bod. De geschiedenis wordt helemaal terug tot leven gewekt door gebruik te maken van memoires en dagboekfragmenten. Ik heb mijn vingers afgelikt na de honderden pagina's over de roerige interbellumjaren in Berlijn. Een paar weken geleden toen ik Berlijn opnieuw bezocht, bekeek ik de stad met nieuwe ogen. Berlijn is d\\u00e9 stad van de 20ste eeuw. Elke beschreven gebeurtenis loopt over van emotie. Dat doet hij door zijn subjecten goed uit te kiezen. En eens zijn dat de beslissingen van politici, dan weer de opstandige volkeren, maar ook bijvoorbeeld het historisch materialisme dat destijds nog een wereldrevolutie in petto had.\\nHij gebruikt ook een aantal literaire trucs om de spanning op te bouwen, de lezer mee te slepen, en elk deeltje met een knaller te eindigen.\\nMaar ik voelde me in het bijzonder gepriviligeerd omdat Maks perspectief zo dicht bij huis is, waardoor ik me makkelijk met zijn sensibiliteiten kon identiferen. Geschiedenis wordt doorgaans verteld door de overwinnaars, zoals het gezegde gaat. In dezen waren dat de Amerikanen. Zij waren de winnaars van de Tweede Wereldoorlog en de Koude Oorlog, en zij waren vanaf de tweede helft van de 20ste eeuw de dominante economische, politieke en culturele macht. Als men er vandaag op terugkijkt, faalt men zich vaak rekenschap af te leggen van dergelijke subtiliteiten, en dat de kijk op verleden en toekomst is mee veranderd met die verschuiving.\\nMak legt een diepgevoeld humanisme aan de dag en een nederigheid tegenover zijn opgave, een deugd die je elk schrijver kan toewensen. Niet enkel is hij een trots voorvechter van de welvaartstaat, maar daarnaast is hij een multiculturalist. Het feit dat zijn ouders in de jaren 50 een Hongaarse vluchteling in huis hadden genomen, zal er wellicht toe bijgedragen hebben. Zijn sympathi\\u00ebn reiken voorbij landsgrenzen, voorbij IJzeren Gordijnen, en dat voel je aan zijn proza.\\nTen slotte was Mak ook een Amsterdamse student in het revolutiejaar 68, een generatiestrijd die ook de generatie van mijn ouders sterk be\\u00efnvloedde (denk aan het holisme van de New Age, de alternatieve geneeskunde, flower power en al de rest die daaruit voortkwam). Een solidairdere samenleving heeft het ons niet opgeleverd, wel een samengevoegd Europa, en dat is een begin. Van wat ik van hieruit kan zien, is een globaal verbond van welvaartstaten de horizon. Dat is waar we heen moeten, en we hebben onze geschiedenis als gids en leidraad.\\n\",\"similarity\":0.3735808134},{\"texts\":\"Liefde baant in elkeen haar weg om ongehinderd door heggen en omheiningen, boven de daken van het dorp uitgeschreeuwd te worden. In het bevlogen moment van de verliefdheid wordt het nihilisme vertrappeld in de stormloop naar het hoogste punt om van te schreeuwen. Geen aandacht schenkt men nog aan de machtsverdelingen. De liefde overschreeuwd alles.\\n\",\"similarity\":0.371294558}]\n",
    "# json.dumps(json_bs, indent=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In het kosmische dansfeest zweeft de interstellaire DJ die de nevels van de tijd doorklieft, terwijl de melodieën van oneindige genres zintuigen prikkelen en sterrenstelsels in harmonisch bewegen brengen.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zin = \"Topic clusterIn het kosmische dansfeest zweeft de interstellaire DJ die de nevels van de tijd doorklieft, terwijl de melodieën van oneindige genres zintuigen prikkelen en sterrenstelsels in harmonisch bewegen brengen. Meer weten? Klik hieronder.Generate cluster snippet\"\n",
    "\n",
    "import re\n",
    "\n",
    "re.search(r'Topic cluster(.*?) Meer weten?', zin).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = \"\"\"[{\"texts\":\"Bij dit laatste dacht ik sterk aan Pierre zijn gevoel voor stoerheid, met zijn aggressief werpen van zijn spullen, alsof hij er niet om geeft, en vooral zijn nihilistische, grove relativering van alles wat hij op zijn weg tegenkomt: \\u201cIls font n'importe quoi\\u201d, \\u201c\\u00e7a me fait chi\\u00e9\\u201d, \\u201cputain, \\u00e7a c'est de la merde,\\u201d \\u201crien \\u00e0 foudre,\\u201d \\u201cil faut crever quoi.\\u201d Het \\u2018wij\\u2019 is een genadeloze macht. Het lacht de zwakkeren uit (net als Alex) en het geeft om alles wat sensatie brengt, alles wat de retoriek pittiger maakt.\\nBij een speech van Nicolas Dupont-Aignan in de \\u00e9cole de commerce (hier in Toulouse) dacht ik na over het feit dat alle vragen, alle problematiseringen kennelijk gericht zijn op pragmatiek. Maar wat hier werkelijk op tafel ligt zijn niet de pragmatische redeneringen, deze probleemoplossingen, maar wel de Franse identiteit: \\u201choezeer willen we het karakter van onze staat vrijwaren?\\u201d Met andere woorden, het is alsof iedereen het weet, iedereen het mee-veronderstelt, maar niemand het durft te vragen: is de protectionistische reflex t.o.v. taal en traditie geen kwaal op zich? \\u2018Op zich\\u2019 wordt het niet in overweging genomen.\\nZoals Dupont-Aignan zei: \\u201cEuropa bestaat uit landen die samenwerken.\\u201d Landen worden beschouwd als entiteiten met een specifieke, onvervreemdbare eigenheid.\\nHet was een Gaullist.\\n\",\"similarity\":0.8267167948},{\"texts\":\"Post-it\\u2019s:\\nFrankrijk is een voortrekker geweest in de constructie van het natiestaten-model. Ook het centraal gezag vanuit Parijs had grote weerklank in de rest van de wereld.\\n\",\"similarity\":0.8131709847},{\"texts\":\"columnisme\\n\",\"similarity\":0.812909394}]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"texts\": \"Bij dit laatste dacht ik sterk aan Pierre zijn gevoel voor stoerheid, met zijn aggressief werpen van zijn spullen, alsof hij er niet om geeft, en vooral zijn nihilistische, grove relativering van alles wat hij op zijn weg tegenkomt: \\\\u201cIls font n\\'importe quoi\\\\u201d, \\\\u201c\\\\u00e7a me fait chi\\\\u00e9\\\\u201d, \\\\u201cputain, \\\\u00e7a c\\'est de la merde,\\\\u201d \\\\u201crien \\\\u00e0 foudre,\\\\u201d \\\\u201cil faut crever quoi.\\\\u201d Het \\\\u2018wij\\\\u2019 is een genadeloze macht. Het lacht de zwakkeren uit (net als Alex) en het geeft om alles wat sensatie brengt, alles wat de retoriek pittiger maakt.\\\\nBij een speech van Nicolas Dupont-Aignan in de \\\\u00e9cole de commerce (hier in Toulouse) dacht ik na over het feit dat alle vragen, alle problematiseringen kennelijk gericht zijn op pragmatiek. Maar wat hier werkelijk op tafel ligt zijn niet de pragmatische redeneringen, deze probleemoplossingen, maar wel de Franse identiteit: \\\\u201choezeer willen we het karakter van onze staat vrijwaren?\\\\u201d Met andere woorden, het is alsof iedereen het weet, iedereen het mee-veronderstelt, maar niemand het durft te vragen: is de protectionistische reflex t.o.v. taal en traditie geen kwaal op zich? \\\\u2018Op zich\\\\u2019 wordt het niet in overweging genomen.\\\\nZoals Dupont-Aignan zei: \\\\u201cEuropa bestaat uit landen die samenwerken.\\\\u201d Landen worden beschouwd als entiteiten met een specifieke, onvervreemdbare eigenheid.\\\\nHet was een Gaullist.\\\\n\", \"similarity\": 0.8267167948}, {\"texts\": \"Post-it\\\\u2019s:\\\\nFrankrijk is een voortrekker geweest in de constructie van het natiestaten-model. Ook het centraal gezag vanuit Parijs had grote weerklank in de rest van de wereld.\\\\n\", \"similarity\": 0.8131709847}, {\"texts\": \"columnisme\\\\n\", \"similarity\": 0.812909394}]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(json.loads(json_string.replace('\\n', '\\\\n')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to run my app in ubuntu:\n",
    "```py\n",
    "# http://localhost:5000/ or http://johannes.vc/\n",
    "\n",
    "# wsl -d Ubuntu\n",
    "# /mnt/c/Users/johan/Documents/GitHub/johannes.vc\n",
    "# export PATH=$PATH:/home/johannesvc/.local/bin\n",
    "# gunicorn -w 4 'website:create_app()'\n",
    "\n",
    "# http://127.0.0.1:8000\n",
    "# ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1388"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = 0\n",
    "for word in json_string.split(' '):\n",
    "    for letter in word:\n",
    "        letters += 1\n",
    "letters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "johannes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
